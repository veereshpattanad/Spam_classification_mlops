{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7f38fd6-5a45-4567-a989-9a7fa552ce1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Install Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18460cbd-4ee9-4800-85c0-b3e46ea2a249",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "%pip install torch torchvision scikit-learn datasets mlflow --upgrade --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bce6b404-d6af-4106-a996-12cde0dd0698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5b4cc87-e1f1-4208-b047-8e76624d1b66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16811ad8-6bed-4774-8262-2a68966e5dfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/lib/dbruntime/huggingface_patches/datasets.py:49: UserWarning: The cache_dir for this dataset is /tmp/.hf.data.cache, which is not a persistent path.Therefore, if/when the cluster restarts, the downloaded dataset will be lost.The persistent storage options for this workspace/cluster config are: [UC Volumes].Please update either `cache_dir` or the environment variable `HF_DATASETS_CACHE`to be under one of the following root directories: ['/Volumes/']\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd4b0772bdd434bac5bd67e1ce7855f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/lib/dbruntime/huggingface_patches/datasets.py:18: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406e72425b444c4f8081d13abf9590cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/359k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3614b8afd9364374808ac69e7f56a398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Go until jurong point, crazy.. Available only ...       0\n",
       "1                    Ok lar... Joking wif u oni...\\n       0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3  U dun say so early hor... U c already then say...       0\n",
       "4  Nah I don't think he goes to usf, he lives aro...       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the SMS Spam dataset\n",
    "dataset = load_dataset(\"sms_spam\")\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# Rename columns for clarity\n",
    "df = df.rename(columns={\"label\": \"target\", \"sms\": \"text\"})\n",
    "\n",
    "# Check distribution\n",
    "df[\"target\"].value_counts()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6eaf542a-6520-4d77-8458-ab4035eb1c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Basic Preprocessing and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "607fc06c-3ba9-4c6a-843d-803e03a7747b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"target\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_vec = vectorizer.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "889ca91f-5770-4fa3-a39f-f5dd62eb4f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "004e18c7-5010-493e-b4d8-e2e72a19e47c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train_vec, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_vec, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Simple model\n",
    "class SpamClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SpamClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "model = SpamClassifier(input_size=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9efc834-197b-46dd-b1c0-eea9482da982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Train the Model and Log with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b45565-5fcc-46e5-9750-1f0718a2745b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/18 20:07:25 INFO mlflow.tracking.fluent: Experiment with name '/Users/gutsjts@gmail.com/spam-classification' does not exist. Creating a new experiment.\n",
      "2025/06/18 20:07:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "ðŸ”— View Logged Model at: https://dbc-1fb8b820-d7ca.cloud.databricks.com/ml/experiments/4289177189276222/models/m-adab88afcc4e43f4a06b004ba813070a?o=166373381389351\n",
      "\u001b[31m2025/06/18 20:07:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9363, F1 Score: 0.7437\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"/Users/gutsjts@gmail.com/spam-classification\")\n",
    "\n",
    "def train_model(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        for epoch in range(10):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_test_tensor)\n",
    "            preds_binary = (preds > 0.5).float()\n",
    "\n",
    "        acc = accuracy_score(y_test_tensor, preds_binary)\n",
    "        f1 = f1_score(y_test_tensor, preds_binary)\n",
    "\n",
    "        # Log metrics and model\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "train_model(model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae8d092f-c5c0-4a9d-8151-b98c8a862ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](/Workspace/Users/gutsjts@gmail.com/Spam_classification_mlops/images/mlflow_expirement.png)\n",
    "![](/Workspace/Users/gutsjts@gmail.com/Spam_classification_mlops/images/metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b827b54a-cd25-4dd3-8aaf-4840ab7f2eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register Model to MLflow Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6856e92-56ee-4988-8023-e8b2040701f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/18 20:12:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "ðŸ”— View Logged Model at: https://dbc-1fb8b820-d7ca.cloud.databricks.com/ml/experiments/4289177189276222/models/m-1d06ca461a834e9fb3638457d9515751?o=166373381389351\n",
      "Successfully registered model 'workspace.default.spamclassifiermodel'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6903c5a88e4176b8da9c8f6c836932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model registered to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ”— Created version '1' of model 'workspace.default.spamclassifiermodel': https://dbc-1fb8b820-d7ca.cloud.databricks.com/explore/data/models/workspace/default/spamclassifiermodel/version/1?o=166373381389351\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pytorch\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Preparing signature and input example\n",
    "example_input = X_test_tensor[:5]\n",
    "pred_example = model(example_input)\n",
    "signature = infer_signature(example_input.numpy(), pred_example.detach().numpy())\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=\"spam_model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=\"SpamClassifierModel\"\n",
    "    )\n",
    "\n",
    "print(\"âœ… Model registered to MLflow.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec24887b-b206-49a3-9d66-825bb9409e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](/Workspace/Users/gutsjts@gmail.com/Spam_classification_mlops/images/serving_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83a394cf-0a13-49b7-bbfa-234a5f8d9bb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Testing Model via REST API in databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0264c9e-c356-40fb-8085-a384f4807f19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¬ Prediction response: {'predictions': [[0.5042845010757446]]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Sample email\n",
    "input_email = [\"Congratulations! Youâ€™ve won a free iPhone. Click here to claim now.\"]\n",
    "\n",
    "# Vectorizing with same vectorizer used in training\n",
    "input_vec = vectorizer.transform(input_email).toarray().tolist()\n",
    "\n",
    "# Databricks token and model endpoint\n",
    "DATABRICKS_TOKEN = \"dapi-***REDACTED***\"\n",
    "MODEL_ENDPOINT = \"https://dbc-1fb8b820-d7ca.cloud.databricks.com/serving-endpoints/spamclassifier-endpoint/invocations\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {DATABRICKS_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": input_vec\n",
    "}\n",
    "\n",
    "response = requests.post(MODEL_ENDPOINT, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "print(\"ðŸ“¬ Prediction response:\", response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e231ae3-2ebe-4a12-a21e-c0cc52e385fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "spam_classifier_pytorch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
